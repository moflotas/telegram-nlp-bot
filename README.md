# NLP-telegram-bot

## Описание

Телеграм бот с использованием языковой модели с [huggingface](https://huggingface.co/tinkoff-ai/ruDialoGPT-medium), натренированный на [чате](https://t.me/+s7HAQFTWTGAwMmUy).

## Обучению модели

Было решено тренировать модель на [чате тренировок яндекса](https://t.me/+s7HAQFTWTGAwMmUy), так как этот чат содержит много диалогов, и сам чат модерировался организаторами.

Детали обучения можно изучить в [ipynb ноутбуке](model_train/train.ipynb)

## Телеграм-бот

Для написания телеграм бота была выбрана библиотека [`pyrogram`](https://pyrogram.org) в виду своей эффективности и протокола [`MTProto`](https://core.telegram.org/mtproto)

В ходе тестов было выявлено, что модель в среднем тратит **> 15 секунд** на генерацию ответа пользователю. Если пользователь будет спамить сообщениями, вся вычислительная мощность будет тратиться только исключительно на него, не давая возможности другим людям пообщаться. По этой причине пока модель отвечает на текущее сообщение пользователя, *все последующие игнорируются*.

Для независимости бота от модели (блокирования работы бота из-за синхронной генерации ответа моделью) было решено их разделить на 2 сервиса и соединить при помощи [`RabbitMQ`](https://www.rabbitmq.com/). Бот отправляет кладет запросы на генерацию ответов в очередь, `RabbitMQ` равномерно распределяет их между несколькими запущенными `Docker`ами с моделью, которые таким же образом отправляют ответ назад боту. Таким образом легко горизонтально масштабировать текущее решение, просто запустив больше `Docker`ов с моделью.

## Почему `pyrogram`?

Я подумал, что будет скучно делать просто телеграм бота, и поэтому решил сделать `user-bot`а. Иначе говоря, бота, который будет отвечать от моего имени. `Pyrogram` имеет довольно простой интерфейс для его создания, <s>а людям веселее общаться с моей второй личностью</s>.

## Запуск

Запустить можно при помощи команды

`docker compose up --build -d`

Для увеличения пропускной способности, можно увеличить количество серверов в `docker-compose.yml`

## Попробовать

По вышеописанным причинам, попробовать можно прямо в [чате со мной](https://t.me/moflotas)

Поддерживаемые команды:

- `/help` - вывод сообщения с помощью
- `/delete_history` - очистить контекст
- `/set_context_length <NUMBER>` - изменить длину контекста
- `Тимоха, <MESSAGE>` - активировать генерацию ответа моделью
